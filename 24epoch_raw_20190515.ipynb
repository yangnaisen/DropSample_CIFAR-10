{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from data_utils import CIFAR10DataLoader\n",
    "from network import GetPrediction,build_cifar_10_res_net\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "K.clear_session()\n",
    "K.set_floatx('float32')\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config = config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_classes = 10\n",
    "number_epoch = 24\n",
    "workers =2\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import pad,normalise\n",
    "x_train_raw = normalise(x_train.copy())\n",
    "x_train = normalise(pad(x_train.copy().astype('uint8')).astype('float16'))\n",
    "x_test = normalise(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('float16')\n",
    "y_test = y_test.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int_label = y_train.copy().argmax(axis = 1)\n",
    "y_test_int_label = y_test.copy().argmax(axis = 1)\n",
    "\n",
    "num_train_samples = x_train.shape[0]\n",
    "num_test_samples = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train_index = np.arange(num_train_samples)\n",
    "dropped_train_index = np.array([],dtype = np.int64)\n",
    "train_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_linear_lr(current_epoch,number_epoch):\n",
    "    return np.interp(current_epoch, [0, 5, number_epoch], [0, 0.4, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cifar_10_res_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRReduce(keras.callbacks.Callback):\n",
    "    def __init__(self,selected_x_train,number_epoch,e,batch_size):\n",
    "        super(LRReduce, self).__init__()\n",
    "        self.selected_x_train =selected_x_train\n",
    "        self.number_epoch = number_epoch\n",
    "        self.e = e\n",
    "        self.batch_size = batch_size\n",
    "    def on_batch_begin(self,batch,logs=None): \n",
    "        lr = piecewise_linear_lr(self.e+(batch/(self.selected_x_train.shape[0]/self.batch_size)),\n",
    "                                    self.number_epoch)/self.batch_size\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_sgd = keras.optimizers.SGD(lr = 0.01,momentum=0.9,nesterov=True)\n",
    "model.compile(\n",
    "              loss='categorical_crossentropy', \n",
    "              optimizer=optimizer_sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_prob = 0.00001\n",
    "threshold_portion = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           epoch       train time        train acc        test time         test acc  dropped samples       total time\n",
      "               1               52           0.1563                3           0.1966                0               57\n",
      "               2               42           0.2226                2           0.2786                0              102\n",
      "               3               42           0.3079                2           0.3878                0              147\n",
      "               4               41           0.4749                2           0.5741                0              191\n",
      "               5               43           0.6158                2           0.6594                0              237\n",
      "               6               41           0.6843                2           0.7274                0              281\n",
      "               7               41           0.7230                2           0.7532                0              326\n",
      "               8               41           0.7510                2           0.7840                0              370\n",
      "               9               42           0.7752                2           0.7983                0              415\n",
      "              10               41           0.7942                2           0.8225                0              460\n",
      "              11               42           0.8107                2           0.8201                0              505\n",
      "              12               41           0.8163                2           0.8398                0              549\n",
      "              13               42           0.8280                3           0.8445                0              595\n",
      "              14               42           0.8332                2           0.8559                0              640\n",
      "              15               43           0.8426                2           0.8544                0              686\n",
      "              16               43           0.8517                2           0.8634                0              732\n",
      "              17               42           0.8580                2           0.8614                0              777\n",
      "              18               42           0.8680                2           0.8702                0              822\n",
      "              19               42           0.8732                2           0.8802                0              868\n",
      "              20               42           0.8836                2           0.8834                0              913\n",
      "              21               42           0.8939                2           0.8921                0              958\n",
      "              22               42           0.9021                2           0.9022                0             1004\n",
      "              23               42           0.9161                2           0.9064                0             1049\n",
      "              24               41           0.9295                2           0.9136                0             1094\n"
     ]
    }
   ],
   "source": [
    "print_title = ['epoch','train time','train acc','test time','test acc','dropped samples','total time']\n",
    "print(*(f'{item:>16s}' for item in print_title))\n",
    "\n",
    "for e in range(number_epoch): \n",
    "    epoch_train_start_time = datetime.now()\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(selected_train_index)\n",
    "        \n",
    "    part_batch = selected_train_index.shape[0]%batch_size\n",
    "    \n",
    "    if part_batch!=0:\n",
    "        part_batch_index = selected_train_index[-part_batch:].copy()\n",
    "        selected_train_index = selected_train_index[0:-part_batch].copy()\n",
    "        dropped_train_index = np.concatenate([part_batch_index,dropped_train_index],axis = 0)\n",
    "        \n",
    "    \n",
    "    selected_x_train = x_train[selected_train_index].copy()\n",
    "    selected_y_train = y_train[selected_train_index].copy() \n",
    "    \n",
    "    if len(dropped_train_index)>0:\n",
    "        dropped_x_train = x_train_raw[dropped_train_index].copy() \n",
    "        dropped_y_train = y_train[dropped_train_index].copy()\n",
    "    \n",
    "    train_generator = CIFAR10DataLoader(\n",
    "            selected_x_train,\n",
    "            selected_y_train,\n",
    "            batch_size=batch_size,\n",
    "            crop_size=32,\n",
    "            cutout_size=8,\n",
    "            is_train=True)\n",
    "    \n",
    "    history = GetPrediction()\n",
    "   \n",
    "        \n",
    "    lr_reduce = LRReduce(selected_x_train,number_epoch,e,batch_size)\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=1,\n",
    "        workers=workers,\n",
    "        verbose=0,\n",
    "        use_multiprocessing=False,\n",
    "        validation_data=None,\n",
    "        max_queue_size=10,\n",
    "        shuffle = False,\n",
    "        callbacks=[history,lr_reduce]\n",
    "        )\n",
    "  \n",
    "    selected_prediction = history.prediction.copy()\n",
    "    \n",
    "    dropped_prediction = model.predict(dropped_x_train, batch_size=batch_size).copy()\n",
    "    \n",
    "    train_prediction = np.concatenate([selected_prediction,dropped_prediction],axis=0)\n",
    "    train_prediction_index = np.concatenate([selected_train_index,dropped_train_index],axis=0)\n",
    "    \n",
    "    \n",
    "    max_position = y_train_int_label[train_prediction_index]\n",
    "    sequence_index = np.arange(num_train_samples)\n",
    "    prob_error = 1.0 - train_prediction[(sequence_index,max_position)]\n",
    "    \n",
    "    selected_index_mask = (prob_error>threshold_prob)\n",
    "    dropped_index_mask = (prob_error<=threshold_prob)\n",
    "    \n",
    "    selected_train_index = train_prediction_index[selected_index_mask]\n",
    "    dropped_train_index = train_prediction_index[dropped_index_mask]\n",
    "    \n",
    "    dropped_portion = dropped_train_index.shape[0]/x_train.shape[0]\n",
    "    \n",
    "    if dropped_portion>threshold_portion:\n",
    "        threshold_prob = threshold_prob/10\n",
    "        if threshold_portion<0.9:\n",
    "            threshold_portion=threshold_portion+0.1\n",
    "        else:\n",
    "            threshold_portion=threshold_portion+0.02\n",
    "    \n",
    "    train_accuracy = (train_prediction.argmax(axis=1) == max_position).sum()/num_train_samples\n",
    "    \n",
    "\n",
    "    epoch_train_end_time = datetime.now()\n",
    "    epoch_training_time = (epoch_train_end_time-epoch_train_start_time).seconds\n",
    "    \n",
    "    \n",
    "    test_prediction = model.predict(x_test, batch_size=batch_size).copy() \n",
    "    test_accuracy = (test_prediction.argmax(axis=1)==y_test_int_label).sum()/num_test_samples\n",
    "\n",
    "    epoch_test_time = (datetime.now()-epoch_train_end_time).seconds\n",
    "    total_time = (datetime.now()-train_start_time).seconds\n",
    "    \n",
    "    print_record = [e+1,epoch_training_time,train_accuracy,epoch_test_time,test_accuracy,len(dropped_train_index),total_time]\n",
    "\n",
    "    print(*(f'{item:16.4f}' if isinstance(item, np.float) else f'{item:16}' for item in print_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
